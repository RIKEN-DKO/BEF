{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_id = 'naver/splade-cocondenser-ensembledistil'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\n",
    "    \"Histochemical specificity of cholinesterases to phenylthioacetate\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskedLMOutput(loss=None, logits=tensor([[[ -6.0833,  -8.0931,  -7.5358,  ...,  -7.4679,  -7.2170,  -4.7996],\n",
       "         [ -9.4616, -10.0497,  -9.9420,  ...,  -9.9228, -10.1299,  -8.1783],\n",
       "         [ -7.0096,  -8.4798,  -8.2369,  ...,  -8.2445,  -7.7094,  -5.3451],\n",
       "         ...,\n",
       "         [ -6.3693,  -7.8741,  -7.4466,  ...,  -7.6402,  -7.3879,  -5.2072],\n",
       "         [ -7.3810,  -8.6121,  -8.0993,  ...,  -8.0730,  -8.0244,  -5.6252],\n",
       "         [-20.5680, -16.4817, -16.0739,  ..., -15.9652, -15.0908, -17.0160]]],\n",
       "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer(text, return_tensors='pt')\n",
    "output = model(**tokens)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 30522])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30522])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "vec = torch.max(\n",
    "    torch.log(\n",
    "        1 + torch.relu(output.logits)\n",
    "    ) * tokens.attention_mask.unsqueeze(-1),\n",
    "dim=1)[0].squeeze()\n",
    "\n",
    "vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1998: 0.03310779854655266,\n",
       " 2000: 0.6177812814712524,\n",
       " 2010: 1.005732536315918,\n",
       " 2168: 0.08255530148744583,\n",
       " 2193: 0.011573554016649723,\n",
       " 2368: 1.0316563844680786,\n",
       " 2504: 0.17538274824619293,\n",
       " 2791: 0.19038361310958862,\n",
       " 3012: 1.4128109216690063,\n",
       " 3231: 0.19589324295520782,\n",
       " 3276: 0.08402110636234283,\n",
       " 3366: 0.5248109698295593,\n",
       " 3401: 0.6450810432434082,\n",
       " 3406: 0.7270060777664185,\n",
       " 3563: 1.797067642211914,\n",
       " 3739: 0.018558084964752197,\n",
       " 4179: 1.004936695098877,\n",
       " 4668: 0.20239974558353424,\n",
       " 4742: 0.43958884477615356,\n",
       " 4962: 0.31664133071899414,\n",
       " 5072: 0.7334992289543152,\n",
       " 5250: 0.07509680837392807,\n",
       " 5648: 0.017283421009778976,\n",
       " 5783: 0.40568697452545166,\n",
       " 6370: 0.37177905440330505,\n",
       " 6463: 0.1956566423177719,\n",
       " 6494: 0.28630903363227844,\n",
       " 6693: 0.5737876892089844,\n",
       " 6887: 0.882270097732544,\n",
       " 7730: 0.13819989562034607,\n",
       " 8516: 1.0287171602249146,\n",
       " 8583: 0.29585856199264526,\n",
       " 9007: 0.7726047039031982,\n",
       " 10441: 0.7270888090133667,\n",
       " 10788: 0.19046343863010406,\n",
       " 11460: 0.07744210958480835,\n",
       " 12115: 0.2329363077878952,\n",
       " 12259: 0.9860626459121704,\n",
       " 12735: 0.43772125244140625,\n",
       " 13922: 0.2483038604259491,\n",
       " 14402: 0.34065189957618713,\n",
       " 14621: 1.3160685300827026,\n",
       " 15222: 1.0158939361572266,\n",
       " 15869: 1.2307847738265991,\n",
       " 16221: 0.307249516248703,\n",
       " 16480: 1.0590262413024902,\n",
       " 18714: 0.10023785382509232,\n",
       " 20366: 0.004553663078695536,\n",
       " 24054: 0.8233087062835693}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# extract non-zero positions\n",
    "cols = vec.nonzero().squeeze().cpu().tolist()\n",
    "print(len(cols))\n",
    "\n",
    "# extract the non-zero values\n",
    "weights = vec[cols].cpu().tolist()\n",
    "# use to create a dictionary of token ID to weight\n",
    "sparse_dict = dict(zip(cols, weights))\n",
    "sparse_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# extract the ID position to text token mappings\n",
    "idx2token = {\n",
    "    idx: token for token, idx in tokenizer.get_vocab().items()\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# map token IDs to human-readable tokens\n",
    "sparse_dict_tokens = {\n",
    "    idx2token[idx]: round(weight, 2) for idx, weight in zip(cols, weights)\n",
    "}\n",
    "# sort so we can see most relevant tokens first\n",
    "sparse_dict_tokens = {\n",
    "    k: v for k, v in sorted(\n",
    "        sparse_dict_tokens.items(),\n",
    "        key=lambda item: item[1],\n",
    "        reverse=True\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'specific': 1.8,\n",
       " '##ity': 1.41,\n",
       " '##tera': 1.32,\n",
       " '##chemical': 1.23,\n",
       " 'cho': 1.06,\n",
       " '##en': 1.03,\n",
       " '##yl': 1.03,\n",
       " '##thi': 1.02,\n",
       " 'his': 1.01,\n",
       " '##line': 1.0,\n",
       " '##tate': 0.99,\n",
       " 'ph': 0.88,\n",
       " 'inhibitor': 0.82,\n",
       " 'enzyme': 0.77,\n",
       " '##to': 0.73,\n",
       " 'chemical': 0.73,\n",
       " '##oa': 0.73,\n",
       " '##ce': 0.65,\n",
       " 'to': 0.62,\n",
       " 'concentration': 0.57,\n",
       " '##se': 0.52,\n",
       " 'signal': 0.44,\n",
       " '##lines': 0.44,\n",
       " 'element': 0.41,\n",
       " 'chemistry': 0.37,\n",
       " 'similarity': 0.34,\n",
       " 'gene': 0.32,\n",
       " 'mutation': 0.31,\n",
       " '##ses': 0.3,\n",
       " '##tra': 0.29,\n",
       " 'molecule': 0.25,\n",
       " 'marker': 0.23,\n",
       " 'test': 0.2,\n",
       " 'reaction': 0.2,\n",
       " 'ratio': 0.2,\n",
       " '##ness': 0.19,\n",
       " 'detection': 0.19,\n",
       " 'level': 0.18,\n",
       " '##ivity': 0.14,\n",
       " 'hormone': 0.1,\n",
       " 'same': 0.08,\n",
       " 'relationship': 0.08,\n",
       " 'protein': 0.08,\n",
       " 'mg': 0.08,\n",
       " 'and': 0.03,\n",
       " 'presence': 0.02,\n",
       " 'acid': 0.02,\n",
       " 'number': 0.01,\n",
       " '##chrome': 0.0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_dict_tokens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "events",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
